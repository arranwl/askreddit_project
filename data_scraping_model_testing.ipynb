{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f634d176",
   "metadata": {},
   "source": [
    "<font size=\"10\">Data Scraping and Model Testing</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af849c9",
   "metadata": {},
   "source": [
    "<font size=\"7\">Part 1: Data Scraping</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3326fa2a",
   "metadata": {},
   "source": [
    "<font size=\"5\">This project seeks to see if it is possible to predict the category of score from the Ask Reddit subreddit</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e427d2",
   "metadata": {},
   "source": [
    "<font size=\"3\">To begin, I start by importing all the the needed packages. I've gone back and added packages along the way as packages came up that I needed, but I like to keep all my packages in one place, this way I'm not importing mid work.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1248,
   "id": "7b5319bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import nltk\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from scipy.linalg import diagsvd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5269fca4",
   "metadata": {},
   "source": [
    "<font size=\"3\">Here I create a read only instance of a Reddit app using the Python Reddit API Wrapper (PRAW). This was a package I was looking forward to using, as Reddit a website that I use frequently, and I was excited because of how simple the package looked to scrape data from the site.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "93d3c22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_only = praw.Reddit(client_id=\"Client ID removed for protection\",\n",
    "                        client_secret=\"Client Secret removed for protection\",\n",
    "                        user_agent=\"arranwasslittle_ufl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "46bd9071",
   "metadata": {},
   "outputs": [],
   "source": [
    "askr = read_only.subreddit(\"AskReddit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9704fd69",
   "metadata": {},
   "source": [
    "<font size=\"5\">This function scrapes the new, top, and hot pages of the subreddit</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3171465c",
   "metadata": {},
   "source": [
    "<font size=\"3\">This is my main data scraping funtion. For each page in a sub, it loops through a section and grabs data from each post. I decided on the different data points due to content knowledge as a user as to what could be an indicator for success.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce40f3bb",
   "metadata": {},
   "source": [
    "<font size=\"3\">A note on 'Score_flag': this is the variable that the model will predict on. You see I've categorized the score into three groups: Under 100, between 100 and 1000, and above 1000. These labels were chosen given a bit of exploration into the distribution of scores, and my own knowledge that the majority of posts score under 100, witht the next two groups the more interesting to try and predict.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "id": "69cd8073",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(sub, num_posts):\n",
    "    data_dict = {\"ID\":[], \"Title\":[], \"Score\":[], \"Score_flag\":[], \"NSFW\":[], \"Serious\":[], \"Time\":[]}\n",
    "    pages = [askr.hot(limit=num_posts), \n",
    "             askr.top('week', limit=num_posts/2), \n",
    "             askr.top('month', limit=num_posts/2),\n",
    "             askr.top('year', limit=num_posts/2),\n",
    "             askr.new(limit=num_posts)]\n",
    "    for page in pages:\n",
    "        for post in page:\n",
    "            data_dict[\"ID\"].append(post.id)\n",
    "            data_dict[\"Title\"].append(post.title)\n",
    "            data_dict[\"Score\"].append(post.score)\n",
    "            if (post.score >= 0) & (post.score <= 100):\n",
    "                score_flag = 0\n",
    "            elif (post.score > 100) & (post.score <= 1000):\n",
    "                score_flag = 1\n",
    "            elif (post.score > 1000):\n",
    "                score_flag = 2\n",
    "            else:\n",
    "                score_flag = 3\n",
    "            data_dict[\"Score_flag\"].append(score_flag)\n",
    "            if post.over_18:\n",
    "                nsfw = 1\n",
    "            else:\n",
    "                nsfw = 0\n",
    "            data_dict[\"NSFW\"].append(nsfw)\n",
    "            if post.link_flair_text == \"Serious Replies Only\":\n",
    "                ser = 1\n",
    "            else:\n",
    "                ser = 0\n",
    "            data_dict[\"Serious\"].append(ser)\n",
    "            time = datetime.datetime.utcfromtimestamp(post.created_utc)\n",
    "            hour = int(format(time.hour))\n",
    "            minute = int(format(time.minute))\n",
    "            if minute >= 30:\n",
    "                hour += 1\n",
    "            if hour > 24:\n",
    "                hour = 0\n",
    "            data_dict[\"Time\"].append(hour)\n",
    "    return pd.DataFrame(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "078fdb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = getData(askr, 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4014ff39",
   "metadata": {},
   "source": [
    "<font size='3'>Here is the raw data. We now need to transform the 'Title' data into a normalized word frequency table.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "id": "0e21ac8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Score</th>\n",
       "      <th>Score_flag</th>\n",
       "      <th>NSFW</th>\n",
       "      <th>Serious</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u5nqgm</td>\n",
       "      <td>What famous person’s downfall are you waiting ...</td>\n",
       "      <td>13993</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u5idpj</td>\n",
       "      <td>What can't you believe still exists in 2022?</td>\n",
       "      <td>13682</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u5mnem</td>\n",
       "      <td>What’s the biggest legal scam?</td>\n",
       "      <td>1213</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u5as3p</td>\n",
       "      <td>What’s the most underrated sex act?</td>\n",
       "      <td>11331</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>u586dj</td>\n",
       "      <td>What’s the most, WTF, film you’ve seen?</td>\n",
       "      <td>22199</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4944</th>\n",
       "      <td>u5sn35</td>\n",
       "      <td>Mall Santa's of Reddit, what's the saddest thi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4945</th>\n",
       "      <td>u5smu9</td>\n",
       "      <td>if you die, what will you do?</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4946</th>\n",
       "      <td>u5smtt</td>\n",
       "      <td>What is something that still surprises you to ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4947</th>\n",
       "      <td>u5smrc</td>\n",
       "      <td>What is the craziest thing that you saw happen...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4948</th>\n",
       "      <td>u5smbi</td>\n",
       "      <td>How would you consider a 19 to 22 year old age...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4949 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID                                              Title  Score  \\\n",
       "0     u5nqgm  What famous person’s downfall are you waiting ...  13993   \n",
       "1     u5idpj       What can't you believe still exists in 2022?  13682   \n",
       "2     u5mnem                     What’s the biggest legal scam?   1213   \n",
       "3     u5as3p                What’s the most underrated sex act?  11331   \n",
       "4     u586dj            What’s the most, WTF, film you’ve seen?  22199   \n",
       "...      ...                                                ...    ...   \n",
       "4944  u5sn35  Mall Santa's of Reddit, what's the saddest thi...      1   \n",
       "4945  u5smu9                      if you die, what will you do?      0   \n",
       "4946  u5smtt  What is something that still surprises you to ...      2   \n",
       "4947  u5smrc  What is the craziest thing that you saw happen...      1   \n",
       "4948  u5smbi  How would you consider a 19 to 22 year old age...      0   \n",
       "\n",
       "      Score_flag  NSFW  Serious  Time  \n",
       "0              2     0        0    14  \n",
       "1              2     0        0     8  \n",
       "2              2     0        0    13  \n",
       "3              2     1        0     0  \n",
       "4              2     1        0    22  \n",
       "...          ...   ...      ...   ...  \n",
       "4944           0     0        0    18  \n",
       "4945           0     0        0    18  \n",
       "4946           0     0        0    18  \n",
       "4947           0     0        0    18  \n",
       "4948           0     0        0    18  \n",
       "\n",
       "[4949 rows x 7 columns]"
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec1098e",
   "metadata": {},
   "source": [
    "<font size=\"5\">This function creates a normalized frequency table of the words used in the title</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62de2765",
   "metadata": {},
   "source": [
    "<font size=\"3\">Here we stem each word, add the frequency of that word in the sentence, and append the sentence onto the larger data frame. Then, we replace all the null values with 0, and normalize each row.\n",
    "\n",
    "\n",
    "Stemming is process by which words from the same root are reduced to that root. For example, the words \"sings\" and \"singing\" would both become \"sing\". This way we the meaning of each sentence is preservered and more easily compared.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1093,
   "id": "4eaab782",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanData(data):\n",
    "    snow = nltk.stem.SnowballStemmer('english')\n",
    "    titles = []\n",
    "    df = pd.DataFrame()\n",
    "    for title in data['Title']:\n",
    "        temp = nltk.tokenize.word_tokenize(title)\n",
    "        cut = [snow.stem(word) for word in temp]\n",
    "        row = {}\n",
    "        for stem in cut:\n",
    "            num = False\n",
    "            try:\n",
    "                int(stem)\n",
    "                num = True\n",
    "            except:\n",
    "                if stem in row:\n",
    "                    row[stem] += 1\n",
    "                else:\n",
    "                    row[stem] = 1\n",
    "        df = df.append(row, ignore_index = True)\n",
    "    df = df.fillna(0)\n",
    "    norms = pd.DataFrame(np.sqrt(np.square(df).sum(axis=1)))\n",
    "    df = df.div(norms.iloc[:,0],axis=0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1094,
   "id": "2f8e21c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = cleanData(data1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe63ab7",
   "metadata": {},
   "source": [
    "<font size=\"3\">Here is the cleaned and created 'Title' data. Now we need to concatenate it with the original data set to create our final data frame.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1095,
   "id": "b01cbd7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>what</th>\n",
       "      <th>famous</th>\n",
       "      <th>person</th>\n",
       "      <th>’</th>\n",
       "      <th>s</th>\n",
       "      <th>downfal</th>\n",
       "      <th>are</th>\n",
       "      <th>you</th>\n",
       "      <th>wait</th>\n",
       "      <th>for</th>\n",
       "      <th>...</th>\n",
       "      <th>repel</th>\n",
       "      <th>tweak</th>\n",
       "      <th>vague/unclear</th>\n",
       "      <th>possess</th>\n",
       "      <th>ingest</th>\n",
       "      <th>medicin</th>\n",
       "      <th>cashier</th>\n",
       "      <th>exit</th>\n",
       "      <th>mall</th>\n",
       "      <th>santa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.277350</td>\n",
       "      <td>0.27735</td>\n",
       "      <td>0.27735</td>\n",
       "      <td>0.277350</td>\n",
       "      <td>0.277350</td>\n",
       "      <td>0.27735</td>\n",
       "      <td>0.27735</td>\n",
       "      <td>0.277350</td>\n",
       "      <td>0.27735</td>\n",
       "      <td>0.27735</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.353553</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.353553</td>\n",
       "      <td>0.353553</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.235702</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>0.235702</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.235702</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4944</th>\n",
       "      <td>0.223607</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.223607</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.223607</td>\n",
       "      <td>0.223607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4945</th>\n",
       "      <td>0.301511</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.603023</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4946</th>\n",
       "      <td>0.301511</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.301511</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4947</th>\n",
       "      <td>0.258199</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.258199</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4948</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4949 rows × 3906 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          what   famous   person         ’         s  downfal      are  \\\n",
       "0     0.277350  0.27735  0.27735  0.277350  0.277350  0.27735  0.27735   \n",
       "1     0.333333  0.00000  0.00000  0.000000  0.000000  0.00000  0.00000   \n",
       "2     0.353553  0.00000  0.00000  0.353553  0.353553  0.00000  0.00000   \n",
       "3     0.333333  0.00000  0.00000  0.333333  0.333333  0.00000  0.00000   \n",
       "4     0.235702  0.00000  0.00000  0.471405  0.235702  0.00000  0.00000   \n",
       "...        ...      ...      ...       ...       ...      ...      ...   \n",
       "4944  0.223607  0.00000  0.00000  0.000000  0.000000  0.00000  0.00000   \n",
       "4945  0.301511  0.00000  0.00000  0.000000  0.000000  0.00000  0.00000   \n",
       "4946  0.301511  0.00000  0.00000  0.000000  0.000000  0.00000  0.00000   \n",
       "4947  0.258199  0.00000  0.00000  0.000000  0.000000  0.00000  0.00000   \n",
       "4948  0.000000  0.00000  0.00000  0.000000  0.000000  0.00000  0.00000   \n",
       "\n",
       "           you     wait      for  ...  repel  tweak  vague/unclear  possess  \\\n",
       "0     0.277350  0.27735  0.27735  ...    0.0    0.0            0.0      0.0   \n",
       "1     0.333333  0.00000  0.00000  ...    0.0    0.0            0.0      0.0   \n",
       "2     0.000000  0.00000  0.00000  ...    0.0    0.0            0.0      0.0   \n",
       "3     0.000000  0.00000  0.00000  ...    0.0    0.0            0.0      0.0   \n",
       "4     0.235702  0.00000  0.00000  ...    0.0    0.0            0.0      0.0   \n",
       "...        ...      ...      ...  ...    ...    ...            ...      ...   \n",
       "4944  0.223607  0.00000  0.00000  ...    0.0    0.0            0.0      0.0   \n",
       "4945  0.603023  0.00000  0.00000  ...    0.0    0.0            0.0      0.0   \n",
       "4946  0.301511  0.00000  0.00000  ...    0.0    0.0            0.0      0.0   \n",
       "4947  0.258199  0.00000  0.00000  ...    0.0    0.0            0.0      0.0   \n",
       "4948  0.250000  0.00000  0.00000  ...    0.0    0.0            0.0      0.0   \n",
       "\n",
       "      ingest  medicin  cashier  exit      mall     santa  \n",
       "0        0.0      0.0      0.0   0.0  0.000000  0.000000  \n",
       "1        0.0      0.0      0.0   0.0  0.000000  0.000000  \n",
       "2        0.0      0.0      0.0   0.0  0.000000  0.000000  \n",
       "3        0.0      0.0      0.0   0.0  0.000000  0.000000  \n",
       "4        0.0      0.0      0.0   0.0  0.000000  0.000000  \n",
       "...      ...      ...      ...   ...       ...       ...  \n",
       "4944     0.0      0.0      0.0   0.0  0.223607  0.223607  \n",
       "4945     0.0      0.0      0.0   0.0  0.000000  0.000000  \n",
       "4946     0.0      0.0      0.0   0.0  0.000000  0.000000  \n",
       "4947     0.0      0.0      0.0   0.0  0.000000  0.000000  \n",
       "4948     0.0      0.0      0.0   0.0  0.000000  0.000000  \n",
       "\n",
       "[4949 rows x 3906 columns]"
      ]
     },
     "execution_count": 1095,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1096,
   "id": "81110fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([data1,data2], axis=1)\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1530,
   "id": "7c42ca14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data_model_building_test.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0b848f",
   "metadata": {},
   "source": [
    "<font size='5'>Here is our final data set!</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1099,
   "id": "bb6b024b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Score</th>\n",
       "      <th>Score_flag</th>\n",
       "      <th>NSFW</th>\n",
       "      <th>Serious</th>\n",
       "      <th>Time</th>\n",
       "      <th>what</th>\n",
       "      <th>famous</th>\n",
       "      <th>person</th>\n",
       "      <th>...</th>\n",
       "      <th>repel</th>\n",
       "      <th>tweak</th>\n",
       "      <th>vague/unclear</th>\n",
       "      <th>possess</th>\n",
       "      <th>ingest</th>\n",
       "      <th>medicin</th>\n",
       "      <th>cashier</th>\n",
       "      <th>exit</th>\n",
       "      <th>mall</th>\n",
       "      <th>santa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u5nqgm</td>\n",
       "      <td>What famous person’s downfall are you waiting ...</td>\n",
       "      <td>13993</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0.277350</td>\n",
       "      <td>0.27735</td>\n",
       "      <td>0.27735</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u5idpj</td>\n",
       "      <td>What can't you believe still exists in 2022?</td>\n",
       "      <td>13682</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u5mnem</td>\n",
       "      <td>What’s the biggest legal scam?</td>\n",
       "      <td>1213</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0.353553</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u5as3p</td>\n",
       "      <td>What’s the most underrated sex act?</td>\n",
       "      <td>11331</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>u586dj</td>\n",
       "      <td>What’s the most, WTF, film you’ve seen?</td>\n",
       "      <td>22199</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0.235702</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4943</th>\n",
       "      <td>u5sn5t</td>\n",
       "      <td>Retail associates and cashiers of Reddit , wha...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0.171499</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.171499</td>\n",
       "      <td>0.171499</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4944</th>\n",
       "      <td>u5sn35</td>\n",
       "      <td>Mall Santa's of Reddit, what's the saddest thi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0.223607</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.223607</td>\n",
       "      <td>0.223607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4945</th>\n",
       "      <td>u5smu9</td>\n",
       "      <td>if you die, what will you do?</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0.301511</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4947</th>\n",
       "      <td>u5smrc</td>\n",
       "      <td>What is the craziest thing that you saw happen...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0.258199</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4948</th>\n",
       "      <td>u5smbi</td>\n",
       "      <td>How would you consider a 19 to 22 year old age...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4508 rows × 3913 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID                                              Title  Score  \\\n",
       "0     u5nqgm  What famous person’s downfall are you waiting ...  13993   \n",
       "1     u5idpj       What can't you believe still exists in 2022?  13682   \n",
       "2     u5mnem                     What’s the biggest legal scam?   1213   \n",
       "3     u5as3p                What’s the most underrated sex act?  11331   \n",
       "4     u586dj            What’s the most, WTF, film you’ve seen?  22199   \n",
       "...      ...                                                ...    ...   \n",
       "4943  u5sn5t  Retail associates and cashiers of Reddit , wha...      1   \n",
       "4944  u5sn35  Mall Santa's of Reddit, what's the saddest thi...      1   \n",
       "4945  u5smu9                      if you die, what will you do?      0   \n",
       "4947  u5smrc  What is the craziest thing that you saw happen...      1   \n",
       "4948  u5smbi  How would you consider a 19 to 22 year old age...      0   \n",
       "\n",
       "      Score_flag  NSFW  Serious  Time      what   famous   person  ...  repel  \\\n",
       "0              2     0        0    14  0.277350  0.27735  0.27735  ...    0.0   \n",
       "1              2     0        0     8  0.333333  0.00000  0.00000  ...    0.0   \n",
       "2              2     0        0    13  0.353553  0.00000  0.00000  ...    0.0   \n",
       "3              2     1        0     0  0.333333  0.00000  0.00000  ...    0.0   \n",
       "4              2     1        0    22  0.235702  0.00000  0.00000  ...    0.0   \n",
       "...          ...   ...      ...   ...       ...      ...      ...  ...    ...   \n",
       "4943           0     0        0    18  0.171499  0.00000  0.00000  ...    0.0   \n",
       "4944           0     0        0    18  0.223607  0.00000  0.00000  ...    0.0   \n",
       "4945           0     0        0    18  0.301511  0.00000  0.00000  ...    0.0   \n",
       "4947           0     0        0    18  0.258199  0.00000  0.00000  ...    0.0   \n",
       "4948           0     0        0    18  0.000000  0.00000  0.00000  ...    0.0   \n",
       "\n",
       "      tweak  vague/unclear  possess  ingest  medicin   cashier      exit  \\\n",
       "0       0.0            0.0      0.0     0.0      0.0  0.000000  0.000000   \n",
       "1       0.0            0.0      0.0     0.0      0.0  0.000000  0.000000   \n",
       "2       0.0            0.0      0.0     0.0      0.0  0.000000  0.000000   \n",
       "3       0.0            0.0      0.0     0.0      0.0  0.000000  0.000000   \n",
       "4       0.0            0.0      0.0     0.0      0.0  0.000000  0.000000   \n",
       "...     ...            ...      ...     ...      ...       ...       ...   \n",
       "4943    0.0            0.0      0.0     0.0      0.0  0.171499  0.171499   \n",
       "4944    0.0            0.0      0.0     0.0      0.0  0.000000  0.000000   \n",
       "4945    0.0            0.0      0.0     0.0      0.0  0.000000  0.000000   \n",
       "4947    0.0            0.0      0.0     0.0      0.0  0.000000  0.000000   \n",
       "4948    0.0            0.0      0.0     0.0      0.0  0.000000  0.000000   \n",
       "\n",
       "          mall     santa  \n",
       "0     0.000000  0.000000  \n",
       "1     0.000000  0.000000  \n",
       "2     0.000000  0.000000  \n",
       "3     0.000000  0.000000  \n",
       "4     0.000000  0.000000  \n",
       "...        ...       ...  \n",
       "4943  0.000000  0.000000  \n",
       "4944  0.223607  0.223607  \n",
       "4945  0.000000  0.000000  \n",
       "4947  0.000000  0.000000  \n",
       "4948  0.000000  0.000000  \n",
       "\n",
       "[4508 rows x 3913 columns]"
      ]
     },
     "execution_count": 1099,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a3208f",
   "metadata": {},
   "source": [
    "<font size='7'>Part 2: Model Testing</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1b2379",
   "metadata": {},
   "source": [
    "<font size='3'>This part of the process took the most time. Not shown here is the many iterations of the model. I ended up choosing to reduce the data use SVD to the 1000 most important vectors. This way the training process was sped up.  I also ended up <b>only including text data</b>. I dropped the Not Safe For Work (NSFW) flag, the Serious flag, and the Time, as the model ended up performing better.Next I played around with perceptron layers of different shapes and sizes. The results can be seen below.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f52208",
   "metadata": {},
   "source": [
    "<font size='3'>SVD works by deconstructing the matrix into two orthonormal basis matrices, and one sizing matrix, which when all three are multiplied together we get the original matrix. I used one of the orthonormal matrices to generate the principal components of the original matrix, and took the top k vectors (in this case 1000). While I was able to get similar accuracy scores without it, reducing the data from ~4000 variables to 1000 drastically reduced model training time, and improved testing accuracy by a percent or two. I would suspect that this happens due to removing “clutter” or useless data points, honing in on the most important parts of each data point.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1147,
   "id": "8abeab06",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,7:]\n",
    "y = df.iloc[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1148,
   "id": "3f32d017",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1243,
   "id": "31a5e2e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3606, 3906)"
      ]
     },
     "execution_count": 1243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1241,
   "id": "3f391039",
   "metadata": {},
   "outputs": [],
   "source": [
    "u, s, vt = np.linalg.svd(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1249,
   "id": "9241341a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd = diagsvd(s,3606,3906)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1242,
   "id": "4e351326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3606, 3606)"
      ]
     },
     "execution_count": 1242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1244,
   "id": "5ce86706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3906, 3906)"
      ]
     },
     "execution_count": 1244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1253,
   "id": "56358b70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3606, 3906)"
      ]
     },
     "execution_count": 1253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1502,
   "id": "b71ad481",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_red = (X_train.values)@vt\n",
    "X_train_red_1000 = X_train_red[:,:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1503,
   "id": "e0328344",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_red = (X_test.values)@vt\n",
    "X_test_red_1000 = X_test_red[:,:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1504,
   "id": "e99853cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.02058839, -0.00409303,  0.02159516, ...,  0.01346033,\n",
       "        -0.01571886, -0.0055454 ],\n",
       "       [-0.0274282 , -0.00379476,  0.03273116, ..., -0.00895144,\n",
       "         0.00972526, -0.00430286],\n",
       "       [ 0.10040782, -0.01316268,  0.00766885, ...,  0.00914211,\n",
       "        -0.0019839 , -0.00494012],\n",
       "       ...,\n",
       "       [ 0.00328192, -0.01033232,  0.01340382, ...,  0.00872265,\n",
       "         0.00173925,  0.00073621],\n",
       "       [ 0.01019859,  0.00786623,  0.00240105, ...,  0.01293478,\n",
       "        -0.01239823,  0.00015583],\n",
       "       [-0.04916128, -0.01196779, -0.14119474, ..., -0.0008329 ,\n",
       "        -0.00300044,  0.00321266]])"
      ]
     },
     "execution_count": 1504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_red_1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1418,
   "id": "08dbeb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_cat = keras.utils.to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1481,
   "id": "d0b6e8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(num_features):\n",
    "    model = keras.models.Sequential()\n",
    "\n",
    "    model.add(keras.Input(shape=(num_features,)))\n",
    "    \n",
    "    model.add(keras.layers.Dense(num_features, activation = 'relu', use_bias=False))\n",
    "        \n",
    "    model.add(keras.layers.Dense(1000, activation = 'relu', use_bias=False))\n",
    "        \n",
    "    model.add(keras.layers.Dense(20, activation = 'relu', use_bias=False))\n",
    "    \n",
    "    model.add(keras.layers.Dense(3, activation='softmax', use_bias=False))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cff78f9",
   "metadata": {},
   "source": [
    "<font size='3'>The actual Multi Layer Perceptron (MLP) neural network consisted of 4 layers, 3 of which were hidden layers and the last of which outputted a probability vector for the category predictions. A MLP works by layering nodes with functions that are fitted with weights. That means each data point is weighted and summed, then put into an activation function. The layers of perceptrons were all fitted with “ReLu” activation nodes. The ReLu function is simple, where it takes in a value and outputs the value, or 0 if the value is less than 0. So as each data point is passed through a “wall” of nodes, the output is an output vector of the size of that many nodes. The process is repeated until the last layer, where the last layer uses the softmax activation function to predict a probability vector. The softmax activation function can be seen here: </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0f0119",
   "metadata": {},
   "source": [
    "<font size='6'>$$\\text{Softmax}(x_{i}) = \\frac{\\exp(x_i)}{\\sum_j \\exp(x_j)}$$ </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6686b6",
   "metadata": {},
   "source": [
    "<font size='3'>Another important feature about the network is that I used cross entropy for the loss function. The cross entropy equation is a common function to measure how different two probability distributions are, since when the two are identical the cross entropy is simply the entropy of the probability distribution. Below is the equation for cross entropy where $p$ is the true probability (which would be a vector of size three like [0,0,1] indicating it has the label 2) and $q$ is the network’s predicted probability distribution. This loss function is what the networks uses gradient descent on, minimizing the loss function of the actual and predicted probability vector.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9200f64d",
   "metadata": {},
   "source": [
    "<font size='6'>$$X(p,q) = \\sum_i p_i log_2(\\frac{1}{q_i})$$ </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1509,
   "id": "eca7b1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_202\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_694 (Dense)            (None, 1000)              1000000   \n",
      "_________________________________________________________________\n",
      "dense_695 (Dense)            (None, 1000)              1000000   \n",
      "_________________________________________________________________\n",
      "dense_696 (Dense)            (None, 20)                20000     \n",
      "_________________________________________________________________\n",
      "dense_697 (Dense)            (None, 3)                 60        \n",
      "=================================================================\n",
      "Total params: 2,020,060\n",
      "Trainable params: 2,020,060\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(X_train_red_1000.shape[1])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1510,
   "id": "c80ebe16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "37/37 [==============================] - 1s 12ms/step - loss: 0.9169 - accuracy: 0.5821\n",
      "Epoch 2/15\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 0.8335 - accuracy: 0.6034\n",
      "Epoch 3/15\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 0.7307 - accuracy: 0.6753\n",
      "Epoch 4/15\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.5585 - accuracy: 0.7612\n",
      "Epoch 5/15\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.3694 - accuracy: 0.8392\n",
      "Epoch 6/15\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 0.2327 - accuracy: 0.8957\n",
      "Epoch 7/15\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 0.1344 - accuracy: 0.9673\n",
      "Epoch 8/15\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 0.1013 - accuracy: 0.9703\n",
      "Epoch 9/15\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 0.1206 - accuracy: 0.9603\n",
      "Epoch 10/15\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.0946 - accuracy: 0.9762\n",
      "Epoch 11/15\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.0365 - accuracy: 0.9903\n",
      "Epoch 12/15\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 0.0233 - accuracy: 0.9953\n",
      "Epoch 13/15\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.0215 - accuracy: 0.9961\n",
      "Epoch 14/15\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 0.0178 - accuracy: 0.9950\n",
      "Epoch 15/15\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 0.0119 - accuracy: 0.9969\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_red_1000, y_train_cat, batch_size = 100, epochs = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1512,
   "id": "ae58dcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_probs = model.predict(X_test_red_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1513,
   "id": "a89928e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(y_pred_probs, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1514,
   "id": "1c47fb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame(y_pred, columns=['y_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1515,
   "id": "cddfe929",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions['y_test'] = y_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0ebd96",
   "metadata": {},
   "source": [
    "<font size='5'>Model Analysis</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde3ebaa",
   "metadata": {},
   "source": [
    "<font size='3'>Here we can see the confusion matrix, accuracy score, precision, and recall. Given these, we can see that the model gets that the majority of posts should be a 0, however it struggles with the 1 label. While this model is not necessarily a top performed, given the data set, these were the top performing hyperparamters.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1529,
   "id": "e2746bf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATgAAAEGCAYAAADxD4m3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAiqklEQVR4nO3deZhU1bnv8e+PQWYQZLAFFExwAKMYEccQ4xDQDOi5GjEx8SRGMcE4nhgcEs1AknPjdBJnozfEMXg0kTgr0RijooATo6KgTAINyKSi3f3eP2q3FNJdXQXdVNXu3+d59tNVq/Ze+6Wf6pe119p7LUUEZmZp1KLYAZiZNRUnODNLLSc4M0stJzgzSy0nODNLrVbFDiBb924to1/f1sUOo2S9/mr7YodQ+tq3LXYEJe3DDe/xUdX72po6hn+pQ6xYWZ3XvlNf3fBoRIzYmvNtjZJKcP36tuaFR/sWO4ySNbzPfsUOoeRpjz2KHUJJe372TVtdR+XKaiY/2ievfVtXvNl9q0+4FUoqwZlZOQiqo6bYQeTFCc7MChJADeXxgIATnJkVrIbyaMF5FNXMChIEH0dNXls+JLWU9JKkB5L33SQ9LumN5GfXrH0vlDRX0hxJwxuq2wnOzAoSQDWR15ans4FZWe/HApMiYgAwKXmPpIHAKGAQMAK4TlLLXBU7wZlZwWqIvLaGSOoDfAX4Y1bxSGB88no8cGxW+d0RsSEi5gFzgaG56ncfnJkVJIDq/Gch6i5pStb7myIi+16Vq4ELgE5ZZb0iYglARCyR1DMp7w08n7XfwqSsXk5wZlawAoYYKiNiSF0fSPoqsCwipko6LI+66rpBOWemdYIzs4JEYf1ruRwCfF3SMUBboLOk24GlkiqS1lsFsCzZfyGQ/SRAH2BxrhO4D87MChIBH+e55a4nLoyIPhHRj8zgwT8i4mRgInBKstspwP3J64nAKEltJPUHBgAv5DqHW3BmViBRXefVYqP5LTBB0qnAO8AJABExQ9IEYCZQBYyJiJwPxTrBmVlBAqhp5AcZIuIp4Knk9QrgiHr2GweMy7deJzgzK1gTt+AajROcmRUkc6OvE5yZpVAAH0d5jE86wZlZQQJRXSY3YDjBmVnBasKXqGaWQu6DM7MUE9XugzOzNMrM6OsEZ2YpFCE+ipzTsJUMJzgzK1iN++DMLI0ygwy+RDWzVPIgg5mllAcZzCzVqn2jr5mlUSA+jvJIHeURpZmVDA8ymFlqBfIlqpmllwcZykR1NfxoxG7sUPExv/zzPJ7+exduu2JHFrzRlt8/9Dq77fPBJvsvW9ia0w7bg5PPf5cTfrC8SFFve+dd/jYHHLma9ypbMfrIgQDsOvB9zvrtO2zXJqiuEtdc3Jc5L3cocqTF0af3Gi4c+8wn73fccR233b433Xf4gAOGLqKqqgWLl3TkyqsPZP367YoY6daLoFFuE5HUFngaaEMmF/1vRFwq6TLgNKD2D+yiiHgoOeZC4FSgGjgrIh7NdY4mTcOSRkiaI2mupLFNea4t9bc/9qDvgA2fvO+3x4f87I/z+dyB6+vc/4bLerP/4Wu3VXgl47F7unHxyZ/dpOz7Fy/i9qsq+OHwPfnzFRWcevGiIkVXfAsXdWbMj45hzI+O4Udnj2DDhlY8+2xfpr20I6N/eAw/OPMYFi3uxInfmFHsULdaZpChZV5bAzYAh0fEPsBgYISkA5PProqIwclWm9wGkll9axAwArhOUs6TNFmCS058LXA0MBA4KQmwZCxf3JoXJnXm6G+u+KRs5wEb6PvZDXXu/+zDXajY+SN22e3DbRViyZg+uRNr39v0uxQBHTpmFjXq0KmalUtbFyO0kjN4n6UsWdKRZcs7MO2lCmpqMn9ms2d3p/sO7xc5usZRTYu8tlwiY13ytnWy5VrOZiRwd0RsiIh5wFxgaK5zNGULbigwNyLeioiPgLuTAEvGDZf25vuXLEZ5/BY+fL8FE67rycnnv9v0gZWJGy7rw/cvWcTtL7zGaT9dxK2/2anYIZWELw57m6f+uctm5V8+6k2mTC3/31EgaiK/DeguaUrWdnp2XZJaSnqZzOLOj0fE5OSjMyW9KulWSV2Tst7AgqzDFyZl9WrKBFdwMNvS8493ZvvuVQzY+4OGdwb+/LsdOe605bTrUNPEkZWPr36nkht/3oeTh36OGy/rw3mXv1PskIquVatqDjxgEf96ZudNykedOJ3q6hb848l+xQmskRXQgquMiCFZ203Z9UREdUQMJrNK/VBJewHXA58hc9m6BLgi2b2uoducCxg25SBDXsEkGf10gJ17b7sxj5kvduD5xzrz4qSBfLRBvL+2Jf995s785Jq6/0hnv9SeZx7cnlt+tRPr1rRELYLt2gQjv1e5zWIuNUcdv4Lrf9YHgKcf2J5zfvd2kSMqviFDljD3za689167T8qOPOItDth/EWMvPoK6/yzKS2Zd1MZtG0XEe5KeAkZExOW15ZJuBh5I3i4E+mYd1gdYnKvepswoeQWTZPSbAIbs07aRl5Ot3/cuWsL3LloCwCvPduR/b+hRb3IDuPJvcz95fdvlO9K2Q3WzTm4AK5a2Zu+D1vHqc50YfMhaFs9rU+yQiu6wYfM3uTzdb7/FnHD8TC74yZFs2JCWmxYaZ2V7ST2Aj5Pk1g44EvhvSRURsSTZ7ThgevJ6InCnpCuBnYABwAu5ztGUv/EXgQGS+gOLyIx+fLMJz9co/v1wF667pDerV7Tip9/elc8M+oBf3/VWscMqurHXzGPvg9bSpVsVt7/4GrddUcHVF+zCD36+gJat4KMN4uqfbN7v1Jy0aVPF5/d9l99fs7Hfe8wZU2jduoZfj/sHkBlo+MO1OfvFS15m2cBGmfCyAhifDEi2ACZExAOSbpM0ODnVfGA0QETMkDQBmAlUAWMiojrXCRTRdI0mSccAVwMtgVsjYlyu/Yfs0zZeeLRvrl2ateF99it2CCVP++xR7BBK2vOzb2LN+sVb1fzqPWj7+OGEQ/Pa95K9HpwaEUO25nxbo0nbzMn9Kw815TnMbNvzfHBmlkqZ+eDKY7DECc7MCuQZfc0spTK3ibgFZ2YpVPssajlwgjOzgnm6JDNLpcx0Sb5ENbOUch+cmaVSZjYRX6KaWQplHtVygjOzVHILzsxSzE8ymFkqeRTVzFLNl6hmlkq1azKUAyc4MytIAFVuwZlZWvkS1czSKcrnErU80rCZlYzaCS/z2XKR1FbSC5JekTRD0s+T8m6SHpf0RvKza9YxF0qaK2mOpOENxeoEZ2YFK2Dh51w2AIdHxD5k1kAdIelAYCwwKSIGAJOS90gaSGbxqkHACOC6ZMGaejnBmVlBaie83NoEFxnrkretky2AkcD4pHw8cGzyeiRwd0RsiIh5wFwg5xJlTnBmVpBAVNW0yGsDukuakrWdnl2XpJaSXgaWAY9HxGSgV+26qMnPnsnuvYEFWYcvTMrq5UEGMytYAY9qVeZaNjBZ13SwpO2Bv0raK0dddZ0057qnTnBmVpho/PngktXtnyLTt7a0dnV7SRVkWneQabFlL5zcB1icq15foppZQRqrD05Sj6TlhqR2wJHAbGAicEqy2ynA/cnricAoSW0k9QcGAC/kOodbcGZWsEZqwVUA45OR0BbAhIh4QNJzwARJpwLvACcARMQMSROAmUAVMCa5xK2XE5yZFSQQ1TVbf/EXEa8C+9ZRvgI4op5jxgHj8j2HE5yZFczzwZlZKkUTDDI0FSc4MytYOMGZWTqVz8P2TnBmVjC34LbAG7O35ysHf73YYZSsFm0rix1Cyat5ZXaxQyht1R9udRURUF3jBGdmKeVRVDNLpcCXqGaWWh5kMLMUi5xzeJQOJzgzK5gvUc0slTKjqOUxEZETnJkVzJeoZpZavkQ1s1QK5ARnZulVJleoTnBmVqCA8KNaZpZW5XKJWh5jvWZWUiLy23KR1FfSk5JmSZoh6eyk/DJJiyS9nGzHZB1zoaS5kuZIGt5QnPW24CT9gRyX2hFxVkOVm1n6NOKzqFXA+RExTVInYKqkx5PProqIy7N3ljQQGAUMAnYCnpC0W66FZ3Jdok7ZutjNLJUCaIQEl6xaX7uC/VpJs8i9Uv1I4O6I2ADMkzQXGAo8V98B9Sa4iBif/V5Sh4hYX0D8ZpZSjX2jr6R+ZFbYmgwcApwp6TtkGlrnR8QqMsnv+azDFpI7ITbcByfpIEkzgVnJ+30kXbcl/wgzSwMRNfltQHdJU7K20zerTeoI3AucExFrgOuBzwCDybTwrvjkxJvLmWrzGUW9GhhOZlVpIuIVScPyOM7M0ir/FlxlRAyp70NJrckktzsi4j6AiFia9fnNwAPJ24VA36zD+wCLc508r1HUiFjwqaKcq0mbWYpFZpAhny0XSQJuAWZFxJVZ5RVZux0HTE9eTwRGSWojqT8wAHgh1znyacEtkHQwEJK2A84iuVw1s2aqcfrgDgG+Dbwm6eWk7CLgJEmDk7PMB0YDRMQMSROAmWRGYMfkGkGF/BLcGcD/kOnMWwQ8Cowp8B9iZqnSKKOoz9RT0UM5jhkHjMv3HA0muIioBL6Vb4Vm1gzUFDuA/OQzirqrpL9LWi5pmaT7Je26LYIzsxJUex9cPluR5TPIcCcwAaggc/fwPcBdTRmUmZW2xnhUa1vIJ8EpIm6LiKpku53ymS3FzJpC5LkVWa5nUbslL5+UNBa4m0zIJwIPboPYzKxUlcDlZz5yDTJMJZPQav8lo7M+C+CXTRWUmZU2lUDrLB+5nkXtvy0DMbMyEYI0TXgpaS9gINC2tiwi/txUQZlZiSv3FlwtSZcCh5FJcA8BRwPPAE5wZs1VmSS4fEZRjweOAN6NiO8C+wBtmjQqMytt5T6KmuWDiKiRVCWpM7AMSN2Nvrfe+wQfvN+KmmpRXS3OOXUYh35pMd88dQ59+63j3O9/gbmzty92mEXTvWID//W7uXTt/jER8PDdvbh/fAXfOmsBI76xlNUrWwMw/oqdefGfXYscbXGcd/nbHHDkat6rbMXoIwcCsOvA9znrt++wXZugukpcc3Ff5rzcociRbqVGmvByW8gnwU2RtD1wM5mR1XU08AQ/gKRbga8CyyJir60Jclu58MyDWLN6Y+P07bc6Me6i/TnzgleLGFVpqK4SN/9mF96c0ZF2Har5/d9e5aV/dwHgb/9vJ+69ZaciR1h8j93TjYl/6sGPr57/Sdn3L17E7VdVMOXJLux/+GpOvXgRF5ywW/GCbCRlP4paKyJ+mLy8QdIjQOeIyOcv/k/ANZRxX92CtzsVO4SSsWr5dqxavh0AH6xvyYI327FDr4+KHFVpmT65E736bNikLAI6dMxMeNGhUzUrl7YuRmiNr9wTnKTP5/osIqblqjgink6mIS4LEfDLq5+HEA/fvwuP3L9LsUMqWT17f8hnBq5nzisdGbjfWr727Xc54rjlvPFaB27+TT/WrfFqlLVuuKwPv75jLqf9dBFqAeeOLP/WG6SjBXdFjs8COLwxAkimMD4doG3L4rWYfnzGoaysbEuXrhv41dXPs+Dtjsx4eYeixVOq2rav5pJrX+fGX/Xj/XWtePCOXtx1TR8i4DvnLuC0C+dz1YWfLXaYJeOr36nkxp/34ZmHujLsq6s47/J3GHvSgGKHtfXKpA+u3lHUiPhSjq1RkltynpsiYkhEDNmuZfvGqrZgKyszt/itXtWG557ekd33fK9osZSqlq1quOTaOTw5sTvPPpZJ/u+t2I6amszsrQ//pSe77bOuyFGWlqOOX8EzD20PwNMPbM9ug1OwblO+I6gl0Mrzws9Am7ZVtGtf9cnrzw9dzttvuf9tU8E5v3mTBXPb8ddbNw4odO2xsR/u4C+v5O3Xi/efVClasbQ1ex+USfqDD1nL4nkpucOqTBKcO0uArt02cPFvMsvAtmxZwz8f783UyT05aNgSzjhvOl22/4jLLp/MW2904WfnHljkaItj0H5rOfK4SubNbs81E18BMreEfPFrley653oIsXRRG35/SeruIMrb2GvmsfdBa+nSrYrbX3yN266o4OoLduEHP19Ay1bw0QZx9U/S0berMpnwUtFEkzZJuovMExDdgaXApRFxS65jurTZMQ7u7cmD61OzrLLYIZS8mg83NLxTMza5+jHWxMqt6kBr07dv9Dn73Lz2fevH50/NtapWU8tnRl9JOlnSz5L3O0sa2tBxEXFSRFREROuI6NNQcjOz8qDIf8tZj9RX0pOSZkmaIenspLybpMclvZH87Jp1zIWS5kqaI2l4Q7Hm0wd3HXAQcFLyfi1wbR7HmVlaNc6U5VVkVq3fEzgQGCNpIDAWmBQRA4BJyXuSz0YBg4ARwHWSWuY6QT4J7oCIGAN8CBARq4Dt8jjOzNKqEQYZImJJ7f20EbGWzHKkvYGRwPhkt/HAscnrkcDdEbEhIuYBc4GcV5P5JLiPkywZAJJ6UDZr6phZUyjgErW7pClZ2+l11pd5KGBfYDLQKyKWQCYJAj2T3XoD2YvQL0zK6pXPKOrvgb8CPSWNIzO7yCV5HGdmaRQFjaJWNjTIIKkjcC9wTkSsySx4X/eudUdTv3yeRb1D0lQyUyYJODYivLK9WXPWSDdfSGpNJrndERH3JcVLJVVExBJJFWRmMIJMi61v1uF9gMW56s9nFHVn4H3g78BEYH1SZmbNVSP0wSnTVLsFmBURV2Z9NBE4JXl9CnB/VvkoSW0k9QcG0MDMRvlcoj7IxsVn2gL9gTlkRjLMrBlqpIftDwG+Dbwm6eWk7CLgt8AESacC7wAnAETEDEkTgJlkRmDHRER1rhPkc4n6uez3ySwjo+vZ3cwsLxHxDHX3q0GmS6yuY8YB4/I9R8GPakXENEn7F3qcmaVICTxnmo98Fp05L+ttC+DzwPImi8jMSltho6hFlU8LLntajSoyfXL3Nk04ZlYW0tCCS27w7RgRP95G8ZhZiRMpmNFXUquIqMo1dbmZNVPlnuDI3F/yeeBlSROBe4BPpiPNuinPzJqTPGYKKRX59MF1A1aQWYOh9n64AJzgzJqrFAwy9ExGUKezMbHVKpP8bWZNIQ0tuJZAR7bgAVczS7kyyQC5EtySiPjFNovEzMpDiSwok49cCa48Fj40s20uDZeodT4LZmZW9i24iFi5LQMxs/KRpke1zMw2SkkfnJnZZkT5dNA7wZlZ4dyCM7O0SsMoqplZ3cokweWzLqqZ2UbJhJf5bA2RdKukZZKmZ5VdJmmRpJeT7Ziszy6UNFfSHEnDG6rfCc7MCtcIq2ol/gSMqKP8qogYnGwPAUgaCIwis+DVCOC6ZM7KejnBmVnBCljZPqeIeBrI957bkcDdEbEhIuYBc4GhuQ5wgjOzwuXfgusuaUrWdnqeZzhT0qvJJWzXpKw3sCBrn4VJWb1KapDh4y6tWTIiZ7zNWo8b3il2CCVv5XcPKnYIJa36/n83Sj0FjKJWRsSQAqu/HvglmRT5S+AK4HtswcxGJZXgzKwMBE064WVELK19Lelm4IHk7UKgb9aufYDFueryJaqZFaR20ZnG6IOrs36pIuvtcWQm3QWYCIyS1EZSf2AAmaUV6uUWnJkVrpHug5N0F3AYmb66hcClwGGSBidnmQ+MBoiIGZImADPJLGE6JiKqc9XvBGdmBVM0ToaLiJPqKL4lx/7jgHH51u8EZ2aF8WwiZpZmfhbVzFLLE16aWXq5BWdmqZSyle3NzDblBGdmaVR7o285cIIzs4KppjwynBOcmRXG98GZWZr5NhEzSy+34MwsrTzIYGbpFEAjPWzf1JzgzKxg7oMzs1TyfXBmll4RvkQ1s/RyC87M0qtMEpwXnTGzgjXWojPJuqfLJE3PKusm6XFJbyQ/u2Z9dqGkuZLmSBreUP1OcGZWmACqI7+tYX8CRnyqbCwwKSIGAJOS90gaCIwCBiXHXCepZa7KneDMrGCN1YKLiKeBlZ8qHgmMT16PB47NKr87IjZExDxgLjA0V/1OcGZWuNqR1Ia2zHKAU7K20/OovVdELMmcJpYAPZPy3sCCrP0WJmX18iCDmRWsgFHUyogY0linraMsZyRuwZlZYaKAbcssrV3dPvm5LClfCPTN2q8PsDhXRU5wZlYQAaqOvLYtNBE4JXl9CnB/VvkoSW0k9QcGAC/kqsiXqGZWsMZa2V7SXcBhZPrqFgKXAr8FJkg6FXgHOAEgImZImgDMBKqAMRFRnat+JzgzK0wjzugbESfV89ER9ew/DhiXb/3NNsFd+rUn+cJub7NyfTu+ccOJAIz+4osct+8sVr3fDoBr/jGUf8/dBYDvHjKNY/edTXWN+N2jh/Lcm33rrTuNzrvyHQ44ci3vVbZi9OG7b/LZ8Wcs47SfLeGEvQaxZmXz+Ur99D+e5NDd32bV+naM+v2Jm3x28qEvc/bRz3PkuFNYnXyf/nPYNL4+ZDY1NeLyBw7l+bnl+h0qn2dRm6wPTlJfSU9KmiVphqSzm+pcW+Lvr+zOmXd8ZbPyOybvzUk3ncBJN53wSXLr330lwwe9yfHXn8iZd36FsUf/ixblMl9MI3nsL924+Fv9NyvvsdNH7DtsLUsXti5CVMX1wLTdOWv85t+hXl3WMfSzC1myquMnZf17rOSovd/kxP85kbPGf4WffL28v0ONdR9cU2vKQYYq4PyI2BM4EBiT3IlcEqa9sxOrP2iT176H7T6fR2d8ho+rW7L4vc4sXNWZvXova/jAFJk+uSNrV23eOht92WJu+dVO5fIfeqN6af5OrHl/8+/Qucc8yx8eOXCTq7gv7jmfx19NvkOrOrNgZWcG9Snj71D+98EVVZMluIhYEhHTktdrgVk0cFNeKThx/+n8ZfQELv3ak3RquwGAnp3Ws3TNxv+Nl67pSI9O64sVYsk48MurqXy3NW/NbFfsUErGsD3ms3xNe954t/sm5T26rGfp6o3foWWrO9Kjc5l+h6LJR1EbzTa5TURSP2BfYPK2ON+WumfKIL7+h28y6sYTqFzXnvOOehYA1XF7YURd9xw2H23a1XDSWcv48+92LHYoJaNN64/57mHTuOGJ/Tf7rO47VMv4O9S098E1miZPcJI6AvcC50TEmjo+P732MY6qD4r7P9rK9e2piRYE4r5pezIouQxduqYDvTqv+2S/Xp3XUbmufbHCLAkVu2xgx50/4von5jB+8kx6VHzMtY++TtceHxc7tKLp020NO3Vdw50/uof7/+t2enZez+1j7mWHju+zbHUHenXZ+B3q2WUdlWvK9zukiLy2YmvSBCepNZnkdkdE3FfXPhFxU0QMiYghrdp1aMpwGtS948YEe/ge83hzWTcA/vl6P4YPepPWLavZafs19O22mumLetZXTbMwf3Y7Ttx7EKccMJBTDhjI8iWtGTN8N1Ytb36DDbXeXLoDw3/zn4y8/GRGXn4yy9Z04ORr/w8r1rXn6dn9OGrv5DvUdQ0777CaGQvL+DtUJn1wTTamL0nALcCsiLiyqc6zpX79H0+w3y6L2b79hzx8zm3c8NQQhvRbzG69VgCw+L1OjHtwGABvLe/G4zN35X9/8Beqa8RvH/4CNdG8HgIZe93b7H3QOrp0q+L2KTO57YpePHrXDsUOq6h+9Y0n2G/XzHfogQtu46ZJQ5g4dc86931rWTeemL4rE87OfIf+79/L+DsUQJkMACuaKMtKOhT4F/AaG38dF0XEQ/Ud075n39jt+HObJJ406HHDc8UOoeSt/O5BxQ6hpM2+/yrWVy7Yqs6/Lh12igMHjs5r38emXDa1ER+2L1iTteAi4hnq7ls1s3JXUx5NuOZz27mZNY4yukR1gjOzgpXCCGk+nODMrHBOcGaWTqVxC0g+nODMrDC1q2qVASc4MyuY++DMLL2c4MwslQKocYIzs1RqvEEGSfOBtUA1UBURQyR1A/4C9APmA9+IiFVbUn+ZPgxnZkXVuA/bfykiBmc90jUWmBQRA4BJyfst4gRnZoUJoLomv23LjATGJ6/HA8duaUVOcGZWoICoyW/LLAc4JWs7ffPKeEzS1KzPekXEEsjMDA5s8bxS7oMzs8Llf/lZ2cBsIodExGJJPYHHJc3e+uA2cgvOzApTO4qaz9ZQVRGLk5/LgL8CQ4GlkioAkp9bvDqPE5yZFa4RBhkkdZDUqfY18GVgOjAROCXZ7RTg/i0N05eoZla4xrlNpBfw18zk37QC7oyIRyS9CEyQdCrwDnDClp7ACc7MChMB1dWNUE28BexTR/kK4IitPgFOcGa2JfyolpmllhOcmaVTfiOkpcAJzswKExBRHosyOMGZWeG2/DGsbcoJzswKE+FlA80sxTzIYGZpFW7BmVk6eVUtM0srT1luZmkVQDTCo1rbghOcmRUmonYyy5LnBGdmBQtfoppZapVJC05RQqMhkpYDbxc7jizdgcpiB1HC/PtpWKn9jnaJiB5bU4GkR8j8u/JRGREjtuZ8W6OkElypkTSlgfnkmzX/fhrm31FxecpyM0stJzgzSy0nuNxuKnYAJc6/n4b5d1RE7oMzs9RyC87MUssJzsxSywmuDpJGSJojaa6kscWOp9RIulXSMknTix1LKZLUV9KTkmZJmiHp7GLH1Fy5D+5TJLUEXgeOAhYCLwInRcTMogZWQiQNA9YBf46IvYodT6mRVAFURMS0ZOX2qcCx/g5te27BbW4oMDci3oqIj4C7gZFFjqmkRMTTwMpix1GqImJJRExLXq8FZgG9ixtV8+QEt7newIKs9wvxl9O2kKR+wL7A5CKH0iw5wW1OdZT5Ot4KJqkjcC9wTkSsKXY8zZET3OYWAn2z3vcBFhcpFitTklqTSW53RMR9xY6nuXKC29yLwABJ/SVtB4wCJhY5JisjkgTcAsyKiCuLHU9z5gT3KRFRBZwJPEqmc3hCRMwoblSlRdJdwHPA7pIWSjq12DGVmEOAbwOHS3o52Y4pdlDNkW8TMbPUcgvOzFLLCc7MUssJzsxSywnOzFLLCc7MUssJroxIqk5uOZgu6R5J7beirj9JOj55/UdJA3Pse5ikg7fgHPMlbbb6Un3ln9pnXYHnukzSfxUao6WbE1x5+SAiBiczeHwEnJH9YTITSsEi4vsNzHRxGFBwgjMrNie48vUv4LNJ6+pJSXcCr0lqKel3kl6U9Kqk0ZC5u17SNZJmSnoQ6FlbkaSnJA1JXo+QNE3SK5ImJQ+LnwGcm7QevyCph6R7k3O8KOmQ5NgdJD0m6SVJN1L3c72bkPQ3SVOTedNO/9RnVySxTJLUIyn7jKRHkmP+JWmPRvltWip5ZfsyJKkVcDTwSFI0FNgrIuYlSWJ1ROwvqQ3wb0mPkZnRYnfgc0AvYCZw66fq7QHcDAxL6uoWESsl3QCsi4jLk/3uBK6KiGck7UzmqY89gUuBZyLiF5K+AmySsOrxveQc7YAXJd0bESuADsC0iDhf0s+Sus8ks4jLGRHxhqQDgOuAw7fg12jNgBNceWkn6eXk9b/IPO94MPBCRMxLyr8M7F3bvwZ0AQYAw4C7IqIaWCzpH3XUfyDwdG1dEVHfnG9HAgMzj1wC0DmZ2HEY8B/JsQ9KWpXHv+ksScclr/smsa4AaoC/JOW3A/cls3McDNyTde42eZzDmiknuPLyQUQMzi5I/tDXZxcBP4qIRz+13zE0PO2T8tgHMl0bB0XEB3XEkvezf5IOI5MsD4qI9yU9BbStZ/dIzvvep38HZvVxH1z6PAr8IJmuB0m7SeoAPA2MSvroKoAv1XHsc8AXJfVPju2WlK8FOmXt9xiZy0WS/QYnL58GvpWUHQ10bSDWLsCqJLntQaYFWasFUNsK/SaZS981wDxJJyTnkKR9GjiHNWNOcOnzRzL9a9OUWRTmRjIt9b8CbwCvAdcD//z0gRGxnEy/2X2SXmHjJeLfgeNqBxmAs4AhySDGTDaO5v4cGCZpGplL5XcaiPURoJWkV4FfAs9nfbYeGCRpKpk+tl8k5d8CTk3im4Gnk7ccPJuImaWWW3BmllpOcGaWWk5wZpZaTnBmllpOcGaWWk5wZpZaTnBmllr/H45PKS1fmvTVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(predictions['y_test'], predictions['y_pred'])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp. .plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40516cc9",
   "metadata": {},
   "source": [
    "<font size='3'>Accuracy is a simple metric of all of the true positive and negatives (in this case the diagonal of the confusion matrix) divided by the total number of values.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf7e0ea",
   "metadata": {},
   "source": [
    "<font size='3'>Precision is the true positives divided by the true positives and false positives. In this case it is the sum of each element in the diagonal divided by the sum of their respective column.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664b54f8",
   "metadata": {},
   "source": [
    "<font size='3'>Recall is the true positives divded by the true positives and the false negatives. In this case it is the sum of each element in the diagonal divided by the sum of their respective rows.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1522,
   "id": "31e75dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6419068736141907\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:',(predictions['y_pred'] == predictions['y_test']).sum()/predictions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1518,
   "id": "d8f9f8cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6731707317073171\n",
      "0.43859649122807015\n",
      "0.6086956521739131\n"
     ]
    }
   ],
   "source": [
    "print('Precision for 0:', cm[0,0]/cm[:,0].sum())\n",
    "print('Precision for 1:', cm[1,1]/cm[:,1].sum())\n",
    "print('Precision for 2:', cm[2,2]/cm[:,2].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1526,
   "id": "4a33f18a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall for 0: 0.8214285714285714\n",
      "Recall for 1: 0.26595744680851063\n",
      "Recall for 2: 0.4605263157894737\n"
     ]
    }
   ],
   "source": [
    "print('Recall for 0:', cm[0,0]/cm[0,:].sum())\n",
    "print('Recall for 1:', cm[1,1]/cm[1,:].sum())\n",
    "print('Recall for 2:', cm[2,2]/cm[2,:].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784b632d",
   "metadata": {},
   "source": [
    "<font size='4'>With a satisfactory accuracy rate, the final model can be trained on the entire data set.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8072747",
   "metadata": {},
   "source": [
    "<font size='7'>Time to train the final model!</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1532,
   "id": "c823ad70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>what</th>\n",
       "      <th>famous</th>\n",
       "      <th>person</th>\n",
       "      <th>’</th>\n",
       "      <th>s</th>\n",
       "      <th>downfal</th>\n",
       "      <th>are</th>\n",
       "      <th>you</th>\n",
       "      <th>wait</th>\n",
       "      <th>for</th>\n",
       "      <th>...</th>\n",
       "      <th>repel</th>\n",
       "      <th>tweak</th>\n",
       "      <th>vague/unclear</th>\n",
       "      <th>possess</th>\n",
       "      <th>ingest</th>\n",
       "      <th>medicin</th>\n",
       "      <th>cashier</th>\n",
       "      <th>exit</th>\n",
       "      <th>mall</th>\n",
       "      <th>santa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.277350</td>\n",
       "      <td>0.27735</td>\n",
       "      <td>0.27735</td>\n",
       "      <td>0.277350</td>\n",
       "      <td>0.277350</td>\n",
       "      <td>0.27735</td>\n",
       "      <td>0.27735</td>\n",
       "      <td>0.277350</td>\n",
       "      <td>0.27735</td>\n",
       "      <td>0.27735</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.353553</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.353553</td>\n",
       "      <td>0.353553</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.235702</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>0.235702</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.235702</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4943</th>\n",
       "      <td>0.171499</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.171499</td>\n",
       "      <td>0.171499</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.171499</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.171499</td>\n",
       "      <td>0.171499</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4944</th>\n",
       "      <td>0.223607</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.223607</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.223607</td>\n",
       "      <td>0.223607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4945</th>\n",
       "      <td>0.301511</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.603023</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4947</th>\n",
       "      <td>0.258199</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.258199</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4948</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4508 rows × 3906 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          what   famous   person         ’         s  downfal      are  \\\n",
       "0     0.277350  0.27735  0.27735  0.277350  0.277350  0.27735  0.27735   \n",
       "1     0.333333  0.00000  0.00000  0.000000  0.000000  0.00000  0.00000   \n",
       "2     0.353553  0.00000  0.00000  0.353553  0.353553  0.00000  0.00000   \n",
       "3     0.333333  0.00000  0.00000  0.333333  0.333333  0.00000  0.00000   \n",
       "4     0.235702  0.00000  0.00000  0.471405  0.235702  0.00000  0.00000   \n",
       "...        ...      ...      ...       ...       ...      ...      ...   \n",
       "4943  0.171499  0.00000  0.00000  0.171499  0.171499  0.00000  0.00000   \n",
       "4944  0.223607  0.00000  0.00000  0.000000  0.000000  0.00000  0.00000   \n",
       "4945  0.301511  0.00000  0.00000  0.000000  0.000000  0.00000  0.00000   \n",
       "4947  0.258199  0.00000  0.00000  0.000000  0.000000  0.00000  0.00000   \n",
       "4948  0.000000  0.00000  0.00000  0.000000  0.000000  0.00000  0.00000   \n",
       "\n",
       "           you     wait      for  ...  repel  tweak  vague/unclear  possess  \\\n",
       "0     0.277350  0.27735  0.27735  ...    0.0    0.0            0.0      0.0   \n",
       "1     0.333333  0.00000  0.00000  ...    0.0    0.0            0.0      0.0   \n",
       "2     0.000000  0.00000  0.00000  ...    0.0    0.0            0.0      0.0   \n",
       "3     0.000000  0.00000  0.00000  ...    0.0    0.0            0.0      0.0   \n",
       "4     0.235702  0.00000  0.00000  ...    0.0    0.0            0.0      0.0   \n",
       "...        ...      ...      ...  ...    ...    ...            ...      ...   \n",
       "4943  0.171499  0.00000  0.00000  ...    0.0    0.0            0.0      0.0   \n",
       "4944  0.223607  0.00000  0.00000  ...    0.0    0.0            0.0      0.0   \n",
       "4945  0.603023  0.00000  0.00000  ...    0.0    0.0            0.0      0.0   \n",
       "4947  0.258199  0.00000  0.00000  ...    0.0    0.0            0.0      0.0   \n",
       "4948  0.250000  0.00000  0.00000  ...    0.0    0.0            0.0      0.0   \n",
       "\n",
       "      ingest  medicin   cashier      exit      mall     santa  \n",
       "0        0.0      0.0  0.000000  0.000000  0.000000  0.000000  \n",
       "1        0.0      0.0  0.000000  0.000000  0.000000  0.000000  \n",
       "2        0.0      0.0  0.000000  0.000000  0.000000  0.000000  \n",
       "3        0.0      0.0  0.000000  0.000000  0.000000  0.000000  \n",
       "4        0.0      0.0  0.000000  0.000000  0.000000  0.000000  \n",
       "...      ...      ...       ...       ...       ...       ...  \n",
       "4943     0.0      0.0  0.171499  0.171499  0.000000  0.000000  \n",
       "4944     0.0      0.0  0.000000  0.000000  0.223607  0.223607  \n",
       "4945     0.0      0.0  0.000000  0.000000  0.000000  0.000000  \n",
       "4947     0.0      0.0  0.000000  0.000000  0.000000  0.000000  \n",
       "4948     0.0      0.0  0.000000  0.000000  0.000000  0.000000  \n",
       "\n",
       "[4508 rows x 3906 columns]"
      ]
     },
     "execution_count": 1532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1533,
   "id": "d2837dac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2\n",
       "1       2\n",
       "2       2\n",
       "3       2\n",
       "4       2\n",
       "       ..\n",
       "4943    0\n",
       "4944    0\n",
       "4945    0\n",
       "4947    0\n",
       "4948    0\n",
       "Name: Score_flag, Length: 4508, dtype: int64"
      ]
     },
     "execution_count": 1533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1534,
   "id": "4475ddea",
   "metadata": {},
   "outputs": [],
   "source": [
    "U, S, Vt = np.linalg.svd(X.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1539,
   "id": "ae7085ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_red = ((X.values)@vt)[:,:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1544,
   "id": "eea6614f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cat = keras.utils.to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1548,
   "id": "1ca4c438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_206\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_710 (Dense)            (None, 1000)              1000000   \n",
      "_________________________________________________________________\n",
      "dense_711 (Dense)            (None, 1000)              1000000   \n",
      "_________________________________________________________________\n",
      "dense_712 (Dense)            (None, 20)                20000     \n",
      "_________________________________________________________________\n",
      "dense_713 (Dense)            (None, 3)                 60        \n",
      "=================================================================\n",
      "Total params: 2,020,060\n",
      "Trainable params: 2,020,060\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "final_model = build_model(X_red.shape[1])\n",
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1549,
   "id": "e0782c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.8986 - accuracy: 0.5890\n",
      "Epoch 2/15\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.7800 - accuracy: 0.6617\n",
      "Epoch 3/15\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.6151 - accuracy: 0.7411\n",
      "Epoch 4/15\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.4237 - accuracy: 0.8174\n",
      "Epoch 5/15\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 0.2284 - accuracy: 0.9241\n",
      "Epoch 6/15\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.1236 - accuracy: 0.9643\n",
      "Epoch 7/15\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.0651 - accuracy: 0.9820\n",
      "Epoch 8/15\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.0454 - accuracy: 0.9894\n",
      "Epoch 9/15\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 0.0452 - accuracy: 0.9894\n",
      "Epoch 10/15\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.0324 - accuracy: 0.9927\n",
      "Epoch 11/15\n",
      "46/46 [==============================] - 1s 17ms/step - loss: 0.0268 - accuracy: 0.9931\n",
      "Epoch 12/15\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.0191 - accuracy: 0.9942\n",
      "Epoch 13/15\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 0.0161 - accuracy: 0.9956\n",
      "Epoch 14/15\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 0.0155 - accuracy: 0.9962\n",
      "Epoch 15/15\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 0.0098 - accuracy: 0.9967\n"
     ]
    }
   ],
   "source": [
    "history = final_model.fit(X_red, y_cat, batch_size = 100, epochs = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1550,
   "id": "7d001393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: final_model/assets\n"
     ]
    }
   ],
   "source": [
    "final_model.save('final_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738713ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc96d7e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (python_env)",
   "language": "python",
   "name": "python_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
